#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆå®Œæ•´çš„ä¸­è‹±æ–‡ç‰©å“åç§°æ˜ å°„è¡¨
ä» cs2_case_items_full.csv è¯»å–æ‰€æœ‰ç‰©å“ï¼Œé€šè¿‡ Steam ç¤¾åŒºå¸‚åœºæˆ– BUFF API è·å–ä¸­æ–‡åç§°

ä½¿ç”¨æ–¹æ³•ï¼š
    python generate_cn_name_mapping.py --source buff    # ä» BUFF è·å–ï¼ˆéœ€è¦ cookiesï¼‰
    python generate_cn_name_mapping.py --source steam   # ä» Steam ç¤¾åŒºå¸‚åœºè·å–ï¼ˆæ¨èï¼‰
    python generate_cn_name_mapping.py --manual         # ä½¿ç”¨æ‰‹åŠ¨ç»´æŠ¤çš„æ˜ å°„è¡¨
"""

import argparse
import pandas as pd
import requests
import time
from pathlib import Path
from typing import Dict, Optional, List
import json
from tqdm import tqdm

# Steam ç¤¾åŒºå¸‚åœº APIï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
STEAM_MARKET_SEARCH = "https://steamcommunity.com/market/search/render/"

# å¤–è§‚è‹±æ–‡->ä¸­æ–‡æ˜ å°„
EXTERIOR_CN = {
    "Factory New": "å´­æ–°å‡ºå‚",
    "Minimal Wear": "ç•¥æœ‰ç£¨æŸ", 
    "Field-Tested": "ä¹…ç»æ²™åœº",
    "Well-Worn": "ç ´æŸä¸å ª",
    "Battle-Scarred": "æˆ˜ç—•ç´¯ç´¯"
}

WEARS = ["Factory New", "Minimal Wear", "Field-Tested", "Well-Worn", "Battle-Scarred"]


def get_cn_name_from_steam(item_name_en: str, max_retries: int = 3) -> Optional[str]:
    """
    é€šè¿‡ Steam ç¤¾åŒºå¸‚åœºæœç´¢æ¥å£è·å–ä¸­æ–‡åç§°
    Steam æ”¯æŒé€šè¿‡ l=schinese å‚æ•°è·å–ç®€ä½“ä¸­æ–‡ç»“æœ
    """
    # å°è¯•ä¸åŒçš„æœç´¢ç­–ç•¥
    search_queries = [
        item_name_en,  # å®Œæ•´åç§°
        item_name_en.split(" | ")[0] if " | " in item_name_en else item_name_en,  # åªæœæ­¦å™¨å
    ]
    
    for query in search_queries:
        for attempt in range(max_retries):
            try:
                params = {
                    "query": query,
                    "start": 0,
                    "count": 10,
                    "search_descriptions": 0,
                    "sort_column": "popular",
                    "sort_dir": "desc",
                    "appid": 730,  # CS2
                    "norender": 1,
                    "l": "schinese"  # ç®€ä½“ä¸­æ–‡
                }
                
                response = requests.get(STEAM_MARKET_SEARCH, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    results = data.get("results", [])
                    
                    # æŸ¥æ‰¾åŒ¹é…çš„ç»“æœ
                    for result in results:
                        hash_name = result.get("hash_name", "")
                        name = result.get("name", "")
                        
                        # å¦‚æœè‹±æ–‡åç§°åŒ¹é…ï¼Œè¿”å›ä¸­æ–‡åç§°
                        if item_name_en.lower() in hash_name.lower():
                            # name å­—æ®µæ˜¯ä¸­æ–‡åç§°
                            if name and name != hash_name:
                                return name
                    
                    # å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç»“æœçš„åç§°
                    if results and len(results) > 0:
                        first_name = results[0].get("name", "")
                        if first_name:
                            return first_name
                
                # 429 Too Many Requests - ç­‰å¾…åé‡è¯•
                if response.status_code == 429:
                    time.sleep(2 * (attempt + 1))
                    continue
                    
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    print(f"  âš  è·å–å¤±è´¥ {item_name_en}: {e}")
    
    return None


def get_cn_name_from_buff(item_name_en: str, cookies: Dict[str, str]) -> Optional[str]:
    """
    é€šè¿‡ BUFF API è·å–ä¸­æ–‡åç§°ï¼ˆéœ€è¦ç™»å½• cookiesï¼‰
    """
    try:
        # BUFF æœç´¢ API
        url = "https://buff.163.com/api/market/search"
        params = {
            "game": "csgo",
            "search": item_name_en,
            "page_num": 1,
            "page_size": 10
        }
        
        response = requests.get(url, params=params, cookies=cookies, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            items = data.get("data", {}).get("items", [])
            
            for item in items:
                # BUFF çš„ name å­—æ®µæ˜¯ä¸­æ–‡å
                cn_name = item.get("name", "")
                en_name = item.get("market_hash_name", "")
                
                # åŒ¹é…è‹±æ–‡åç§°
                if item_name_en.lower() in en_name.lower():
                    return cn_name
        
    except Exception as e:
        print(f"  âš  BUFF API é”™è¯¯ {item_name_en}: {e}")
    
    return None


def generate_manual_mapping() -> Dict[str, str]:
    """
    ç”Ÿæˆæ‰‹åŠ¨ç»´æŠ¤çš„å¸¸è§ç‰©å“æ˜ å°„è¡¨
    è¿™äº›æ˜¯æœ€å¸¸è§çš„äº¤æ˜“ç‰©å“ï¼Œå¯ä»¥æ‰‹åŠ¨ç»´æŠ¤
    """
    manual_map = {
        # AK-47 ç³»åˆ—
        "AK-47 | Redline": "AK-47 | çº¢çº¿",
        "AK-47 | Asiimov": "AK-47 | äºŒè¥¿è«å¤«",
        "AK-47 | Fire Serpent": "AK-47 | ç«è›‡",
        "AK-47 | Vulcan": "AK-47 | ç«ç¥",
        "AK-47 | Case Hardened": "AK-47 | æ¡ˆä¾‹ç¡¬åŒ–",
        
        # AWP ç³»åˆ—
        "AWP | Asiimov": "AWP | äºŒè¥¿è«å¤«",
        "AWP | Dragon Lore": "AWP | é¾™ç‹™",
        "AWP | Lightning Strike": "AWP | é—ªç”µçªå‡»",
        "AWP | Hyper Beast": "AWP | è¶…å‡¡é‡å…½",
        
        # M4A4 ç³»åˆ—
        "M4A4 | Asiimov": "M4A4 | äºŒè¥¿è«å¤«",
        "M4A4 | Howl": "M4A4 | åšå«",
        "M4A4 | The Emperor": "M4A4 | å¸ç‹",
        
        # M4A1-S ç³»åˆ—
        "M4A1-S | Hot Rod": "M4A1-S | çƒˆç„°ç¥é©¹",
        "M4A1-S | Golden Coil": "M4A1-S | é»„é‡‘åœˆ",
        
        # Desert Eagle ç³»åˆ—
        "Desert Eagle | Blaze": "æ²™æ¼ ä¹‹é¹° | çƒˆç„°",
        "Desert Eagle | Code Red": "æ²™æ¼ ä¹‹é¹° | æš—çº¢ä»£ç ",
        
        # Glock-18 ç³»åˆ—
        "Glock-18 | Water Elemental": "æ ¼æ´›å…‹18å‹ | æ°´å…ƒç´ ",
        "Glock-18 | Fade": "æ ¼æ´›å…‹18å‹ | æ¸å˜ä¹‹è‰²",
        
        # USP-S ç³»åˆ—
        "USP-S | Kill Confirmed": "USP-S | ç¡®è®¤å‡»æ€",
        "USP-S | Neo-Noir": "USP-S | é»‘è‰²å½±åƒ",
    }
    
    return manual_map


def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆä¸­è‹±æ–‡ç‰©å“åç§°æ˜ å°„è¡¨")
    parser.add_argument("--source", choices=["steam", "buff", "manual"], default="steam",
                        help="æ•°æ®æ¥æºï¼šsteamï¼ˆæ¨èï¼‰/ buffï¼ˆéœ€è¦cookiesï¼‰/ manualï¼ˆæ‰‹åŠ¨æ˜ å°„ï¼‰")
    parser.add_argument("--input", default="data/cs2_case_items_full.csv",
                        help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", default="data/name_mapping.csv",
                        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--buff-cookies", default=None,
                        help="BUFF cookies JSON æ–‡ä»¶è·¯å¾„ï¼ˆä»… --source buff æ—¶éœ€è¦ï¼‰")
    parser.add_argument("--rate-limit", type=float, default=1.0,
                        help="è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è¢«é™æµ")
    
    args = parser.parse_args()
    
    # è¯»å–ç‰©å“æ¸…å•
    print(f"ğŸ“– è¯»å–ç‰©å“æ¸…å•: {args.input}")
    df = pd.read_csv(args.input, encoding="utf-8")
    
    # æå–å”¯ä¸€çš„è‹±æ–‡ç‰©å“å
    if "item_name_en" not in df.columns:
        print("âŒ é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ç¼ºå°‘ item_name_en åˆ—")
        return
    
    items = df["item_name_en"].dropna().unique()
    print(f"âœ… æ‰¾åˆ° {len(items)} ä¸ªå”¯ä¸€ç‰©å“")
    
    # ç”Ÿæˆæ˜ å°„
    mapping = {}
    
    if args.source == "manual":
        print("ğŸ“ ä½¿ç”¨æ‰‹åŠ¨ç»´æŠ¤çš„æ˜ å°„è¡¨")
        mapping = generate_manual_mapping()
        
    elif args.source == "steam":
        print("ğŸŒ ä» Steam ç¤¾åŒºå¸‚åœºè·å–ä¸­æ–‡åç§°...")
        print(f"   è¯·æ±‚é—´éš”: {args.rate_limit} ç§’")
        
        for item in tqdm(items, desc="è·å–ä¸­æ–‡åç§°"):
            cn_name = get_cn_name_from_steam(item)
            if cn_name:
                mapping[item] = cn_name
            time.sleep(args.rate_limit)
    
    elif args.source == "buff":
        if not args.buff_cookies:
            print("âŒ é”™è¯¯ï¼š--source buff éœ€è¦æä¾› --buff-cookies å‚æ•°")
            return
        
        print(f"ğŸŒ ä» BUFF è·å–ä¸­æ–‡åç§°ï¼ˆä½¿ç”¨ cookies: {args.buff_cookies}ï¼‰...")
        
        with open(args.buff_cookies, "r") as f:
            cookies = json.load(f)
        
        for item in tqdm(items, desc="è·å–ä¸­æ–‡åç§°"):
            cn_name = get_cn_name_from_buff(item, cookies)
            if cn_name:
                mapping[item] = cn_name
            time.sleep(args.rate_limit)
    
    # ç”Ÿæˆå®Œæ•´çš„æ˜ å°„è¡¨ï¼ˆåŒ…å«å¤–è§‚å˜ä½“ï¼‰
    print("\nğŸ“‹ ç”Ÿæˆå®Œæ•´æ˜ å°„è¡¨ï¼ˆåŒ…å«å¤–è§‚å˜ä½“ï¼‰...")
    full_mapping = []
    
    for item_en, item_cn in mapping.items():
        # åŸºç¡€åç§°æ˜ å°„
        full_mapping.append({
            "name": item_en,
            "market_hash_name": item_cn
        })
        
        # ä¸ºæ¯ä¸ªå¤–è§‚ç”Ÿæˆæ˜ å°„ï¼ˆç”¨äºå¸‚åœºæœç´¢ï¼‰
        for wear_en, wear_cn in EXTERIOR_CN.items():
            full_name_en = f"{item_en} ({wear_en})"
            full_name_cn = f"{item_cn} ({wear_cn})"
            full_mapping.append({
                "name": full_name_en,
                "market_hash_name": full_name_cn
            })
    
    # ä¿å­˜æ˜ å°„è¡¨
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    df_mapping = pd.DataFrame(full_mapping)
    df_mapping.to_csv(output_path, index=False, encoding="utf-8")
    
    print(f"\nâœ… å·²ç”Ÿæˆæ˜ å°„è¡¨: {output_path}")
    print(f"   åŸºç¡€ç‰©å“: {len(mapping)} ä¸ª")
    print(f"   æ€»æ˜ å°„æ•°: {len(full_mapping)} æ¡ï¼ˆå«å¤–è§‚å˜ä½“ï¼‰")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print("\nğŸ“ æ˜ å°„ç¤ºä¾‹ï¼ˆå‰10æ¡ï¼‰:")
    print(df_mapping.head(10).to_string(index=False))
    
    # ç»Ÿè®¡æœªæ˜ å°„çš„ç‰©å“
    unmapped = set(items) - set(mapping.keys())
    if unmapped:
        print(f"\nâš ï¸  {len(unmapped)} ä¸ªç‰©å“æœªè·å–åˆ°ä¸­æ–‡åç§°:")
        for item in list(unmapped)[:10]:
            print(f"   - {item}")
        if len(unmapped) > 10:
            print(f"   ... è¿˜æœ‰ {len(unmapped) - 10} ä¸ª")


if __name__ == "__main__":
    main()
